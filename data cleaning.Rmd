#code to prepare the data for analysis#last edited Dec 12, 2023 by A. R. Martinig#Delete previous information stored rm(list=ls(all=T))##set wd to the folder with all your csv's in itsetwd("~/Documents/Files/Post-docs/UNSW 2022-2024/Aim 1")options(scipen=999, dplyr.width = Inf, tibble.print_min = 50, repos='http://cran.rstudio.com/') #scipen forces outputs to not be in scientific notation #dplyr.width will show all columns for head() function and tibble.print_min sets how many rows are printed and repos sets the cran mirror#load librariespackages=c("tidyverse", "dplyr", "googlesheets4") #do not put in the showtext package as it messes EVERYTHING up# Install packages not yet installedinstalled_packages <- packages %in% rownames(installed.packages())if (any(installed_packages == FALSE)) {  install.packages(packages[!installed_packages])}# Packages loadinglapply(packages, library, character.only = TRUE)# Read the Google Sheet into a dataframedf <- read.csv("Aim 1 - Aim 1.csv", header=T) %>%	filter(!composite_variable=="Y", !obsID=="TBD") %>%	mutate_if(is.character, as.factor) %>%	select(-c(title, DOI, journal, year, region, country, composite_variable, effect_size_p_value, consider_excluding, needs_second_opinion, cross_checked, data_source, comments)) %>%	#for now I am going to filter out some of the more complicated comparisons	filter(!group_1 %in% c("nonbreeder", "low", "dead")) %>%	group_by(function_needed, study_design) %>%	slice_head(n=10) %>%	droplevels()	summary(df)	table(df$function_needed)	table(df$effect_size)	table(df$effect_size_details)	table(df$effect_size_type)table(df$effect_size_direction)	table(df$effect_size_df)				#export google sheet to CSV to make it easier to work with (it is a pain because it has different file formats for numeric columns, like "lists")write.csv(df, "~/Documents/Files/Post-docs/UNSW 2022-2024/Aim 1/Fitness-and-dispersal-MA/aim 1 data for shinichi.csv")	